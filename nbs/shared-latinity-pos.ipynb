{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Configuring Jupyter notebook"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val myBT = coursierapi.MavenRepository.of(\"https://dl.bintray.com/neelsmith/maven\")\n",
        "interp.repositories() ++= Seq(myBT)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import $ivy.`edu.holycross.shot::ohco2:10.18.2`\n",
        "import $ivy.`edu.holycross.shot.cite::xcite:4.2.0`\n",
        "import $ivy.`edu.holycross.shot::midvalidator:10.0.0`\n",
        "import $ivy.`edu.holycross.shot::latincorpus:2.2.1`\n",
        "import $ivy.`edu.holycross.shot::latphone:2.7.2`"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load corpus from URL"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import edu.holycross.shot.cite._\n",
        "import edu.holycross.shot.ohco2._\n",
        "\n",
        "val hyginusUrl = \"https://raw.githubusercontent.com/neelsmith/hctexts/master/cex/hyginus.cex\"\n",
        "\n",
        "val corpus = CorpusSource.fromUrl(hyginusUrl, cexHeader = true)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create tokenizable corpus\n",
        "\n",
        "Load FST parser output."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val hyginusFstUrl = \"https://raw.githubusercontent.com/neelsmith/hctexts/master/parser-output/hyginus/hyginus-parses.txt\"\n",
        "import scala.io.Source\n",
        "val fstOutput = Source.fromURL(hyginusFstUrl).getLines.toVector"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize corpus according to its orthographic system (here, `Latin23Alphabet`)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import edu.holycross.shot.latin._\n",
        "\n",
        "import edu.holycross.shot.mid.validator._\n",
        "\n",
        "\n",
        "val tcorpus = TokenizableCorpus(corpus, Latin23Alphabet )\n",
        "val wordList =  tcorpus.wordList"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine parser output with tokenized corpus to get a `LatinCorpus` instance."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import edu.holycross.shot.latincorpus._\n",
        "\n",
        "val lc = LatinCorpus.fromFstLines(\n",
        "      corpus,\n",
        "       Latin23Alphabet,\n",
        "     fstOutput,\n",
        "      strict = false\n",
        "    )\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "// This should be the number of distinct analyzed tokens\n",
        "lc.lexemeTokenIndex.size"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "// This is the histogram of recognized lexemes:\n",
        "lc.labelledLexemeHistogram"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "// It would be nice to visualize, so let's use the \n",
        "// plotly library with ammonite sh:\n",
        "// Make plotly libraries available to this notebook:\n",
        "import $ivy.`org.plotly-scala::plotly-almond:0.7.1`"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "// Import plotly libraries, and set display defaults suggested for use in Jupyter NBs:\n",
        "import plotly._, plotly.element._, plotly.layout._, plotly.Almond._\n",
        "repl.pprinter() = repl.pprinter().copy(defaultHeight = 3)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zipf's Law for analyzed lexemes in Hyginus"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val items = lc.labelledLexemeHistogram.frequencies.map(fr => fr.item)\n",
        "val counts = lc.labelledLexemeHistogram.frequencies.map(fr => fr.count)\n",
        "lc.labelledLexemeHistogram\n",
        "val zipf = Vector(\n",
        "  Bar(x = items, y = counts)\n",
        ")\n",
        "plot(zipf)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zipf's Law for analyzed tokens in Hyginus"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val items = lc.tcorpus.lexHistogram.frequencies.map(fr => fr.item)\n",
        "val counts = lc.tcorpus.lexHistogram.frequencies.map(fr => fr.count)\n",
        "lc.labelledLexemeHistogram\n",
        "val zipfTokens = Vector(\n",
        "  Bar(x = items, y = counts)\n",
        ")\n",
        "plot(zipfTokens)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To work out\n",
        "\n",
        "- relation of counts: \n",
        "    - lexical tokens in corpus\n",
        "    - analyzed lexical tokens\n",
        "    - recognized lexemes\n",
        "- PoS distribution:  map each lexeme in lexeme histogram to its PoS \n",
        "\n",
        "(This is OK since lexical ambiguity is effectively 0)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Histogram of disambiguated forms"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val items = lc.formsHistogram.sorted.frequencies.map(fr => fr.item)\n",
        "val counts = lc.formsHistogram.sorted.frequencies.map(fr => fr.count)\n",
        "lc.labelledLexemeHistogram\n",
        "val zipfForms = Vector(\n",
        "  Bar(x = items, y = counts)\n",
        ")\n",
        "plot(zipfForms)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a map of lexeme to  PoS\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val sampleForm = lc.analyzed.map (a => a.analyses(0))\n",
        "val lexemePoSpairing = sampleForm.map (f => f.lemmaId -> f.posLabel)\n",
        "val lexemeToPosMap = lexemePoSpairing.toMap"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val example = \"ls.n16278\"\n",
        "lexemeToPosMap(example)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Map lexeme histogram to PoS histogram"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val freqOpts = lc.lexemeHistogram.frequencies.map(\n",
        "  fr => {\n",
        "    if (lexemeToPosMap.contains(fr.item)) {\n",
        "      Some(edu.holycross.shot.histoutils.Frequency(lexemeToPosMap(fr.item),  fr.count))\n",
        "    } else {\n",
        "      None\n",
        "    }\n",
        "    \n",
        "  })\n",
        "val freqs = freqOpts.flatten"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Look at PoS distribution for top 400 lexemes"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val top400Items = freqs.map(f => f.item).take(400)\n",
        "val top400Counts = freqs.map(f => f.count).take(400)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val top400Freqs = freqs.take(400)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val posGroups = top400Freqs.groupBy(fr => fr.item)\n",
        "val posCounts = posGroups.toVector.map{ case (pos, freqsV) => pos -> freqsV.map(f => f.count).sum }"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val topPosCounts = posCounts.toVector.sortBy( _._2).map{ case(p,c) => edu.holycross.shot.histoutils.Frequency(p,c)}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val topPosHisto = edu.holycross.shot.histoutils.Histogram(topPosCounts).sorted"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val items = topPosHisto.sorted.frequencies.map(fr => fr.item)\n",
        "val counts = topPosHisto.sorted.frequencies.map(fr => fr.count)\n",
        "\n",
        "val topPosPlot = Vector(\n",
        "  Bar(x = items, y = counts)\n",
        ")\n",
        "plot(topPosPlot)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Repeat for second 400 item"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val second400Freqs = freqs.slice(400, 800)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val tier2Groups = second400Freqs.groupBy(fr => fr.item)\n",
        "val tier2Counts = tier2Groups.toVector.map{ case (pos, freqsV) => pos -> freqsV.map(f => f.count).sum }"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val tier2PosCounts = tier2Counts.toVector.sortBy( _._2).map{ case(p,c) => edu.holycross.shot.histoutils.Frequency(p,c)}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val tier2PosHisto = edu.holycross.shot.histoutils.Histogram(tier2PosCounts).sorted"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val items = tier2PosHisto.sorted.frequencies.map(fr => fr.item)\n",
        "val counts = tier2PosHisto.sorted.frequencies.map(fr => fr.count)\n",
        "\n",
        "val tierPosPlot = Vector(\n",
        "  Bar(x = items, y = counts)\n",
        ")\n",
        "plot(tierPosPlot)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Scala (2.12)",
      "language": "scala",
      "name": "scala212"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "nbconvert_exporter": "script",
      "version": "2.12.10"
    },
    "nteract": {
      "version": "0.22.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}