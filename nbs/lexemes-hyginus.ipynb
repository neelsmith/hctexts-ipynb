{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing frequency of lexemes"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuring Jupyter notebook"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val myBT = coursierapi.MavenRepository.of(\"https://dl.bintray.com/neelsmith/maven\")\n",
        "interp.repositories() ++= Seq(myBT)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import $ivy.`edu.holycross.shot::ohco2:10.18.2`\n",
        "import $ivy.`edu.holycross.shot.cite::xcite:4.2.0`\n",
        "import $ivy.`edu.holycross.shot::midvalidator:10.0.0`\n",
        "import $ivy.`edu.holycross.shot::latincorpus:2.2.1`\n",
        "import $ivy.`edu.holycross.shot::latphone:2.7.2`"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load a citable corpus from a URL"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import edu.holycross.shot.cite._\n",
        "import edu.holycross.shot.ohco2._\n",
        "\n",
        "val hyginusUrl = \"https://raw.githubusercontent.com/neelsmith/hctexts/master/cex/hyginus.cex\"\n",
        "val corpus = CorpusSource.fromUrl(hyginusUrl, cexHeader = true)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a tokenizable corpus\n",
        "\n",
        "Combine the citable corpus with an orthographic system to create a tokenizable corpus.\n",
        "\n",
        "Among the many methods of the `TokenizableCorpus` class is a method to generate an alphabetized list of lexical tokens (in colloquial English, a word list).  This can be used as input to a morphological parser.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import edu.holycross.shot.latin._\n",
        "import edu.holycross.shot.mid.validator._\n",
        "\n",
        "val tcorpus = TokenizableCorpus(corpus, Latin23Alphabet )\n",
        "val wordList =  tcorpus.wordList"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a `LatinCorpus`\n",
        "\n",
        "Add output of a morphological parser to the tokenizable corpus to create a `LatinCorpus`."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "// Read output from morphological parser from a URL:\n",
        "val hyginusFstUrl = \"https://raw.githubusercontent.com/neelsmith/hctexts/master/parser-output/hyginus/hyginus-parses.txt\"\n",
        "import scala.io.Source\n",
        "val fstOutput = Source.fromURL(hyginusFstUrl).getLines.toVector"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import edu.holycross.shot.latincorpus._\n",
        "\n",
        "val lc = LatinCorpus.fromFstLines(\n",
        "      corpus,\n",
        "       Latin23Alphabet,\n",
        "     fstOutput,\n",
        "      strict = false\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ## Zipf's Law for analyzed lexemes in Hyginus\n",
        "\n",
        "A `LatinCorpus` has a method to create a histogram of lexemes."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "// This is the histogram of recognized lexemes:\n",
        "lc.labelledLexemeHistogram"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "// It would be nice to visualize, so let's use the \n",
        "// plotly library with ammonite sh:\n",
        "// Make plotly libraries available to this notebook:\n",
        "import $ivy.`org.plotly-scala::plotly-almond:0.7.1`"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "// Import plotly libraries, and set display defaults suggested for use in Jupyter NBs:\n",
        "import plotly._, plotly.element._, plotly.layout._, plotly.Almond._\n",
        "repl.pprinter() = repl.pprinter().copy(defaultHeight = 3)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val items = lc.labelledLexemeHistogram.frequencies.map(fr => fr.item)\n",
        "val counts = lc.labelledLexemeHistogram.frequencies.map(fr => fr.count)\n",
        "\n",
        "val zipf = Vector(\n",
        "  Bar(x = items, y = counts)\n",
        ")\n",
        "plot(zipf)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Scala (2.12)",
      "language": "scala",
      "name": "scala212"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "nbconvert_exporter": "script",
      "version": "2.12.10"
    },
    "nteract": {
      "version": "0.22.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}