{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Distribution of lexical tokens in Hyginus"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuring Jupyter notebook"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val myBT = coursierapi.MavenRepository.of(\"https://dl.bintray.com/neelsmith/maven\")\n",
        "interp.repositories() ++= Seq(myBT)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-02-26T17:34:31.702Z",
          "iopub.execute_input": "2020-02-26T17:34:31.709Z",
          "iopub.status.idle": "2020-02-26T17:34:35.995Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import $ivy.`edu.holycross.shot::ohco2:10.18.2`\n",
        "import $ivy.`edu.holycross.shot.cite::xcite:4.2.0`\n",
        "import $ivy.`edu.holycross.shot::midvalidator:10.0.0`\n",
        "import $ivy.`edu.holycross.shot::latincorpus:2.2.1`\n",
        "import $ivy.`edu.holycross.shot::latphone:2.7.2`"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.status.busy": "2020-02-26T17:34:35.999Z",
          "iopub.execute_input": "2020-02-26T17:34:36.002Z",
          "iopub.status.idle": "2020-02-26T17:34:39.958Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load corpus from URL"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import edu.holycross.shot.cite._\n",
        "import edu.holycross.shot.ohco2._\n",
        "\n",
        "val hyginusUrl = \"https://raw.githubusercontent.com/neelsmith/hctexts/master/cex/hyginus.cex\"\n",
        "\n",
        "val corpus = CorpusSource.fromUrl(hyginusUrl, cexHeader = true)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.status.busy": "2020-02-26T17:34:39.966Z",
          "iopub.execute_input": "2020-02-26T17:34:39.970Z",
          "iopub.status.idle": "2020-02-26T17:34:44.372Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create tokenizable corpus\n",
        "\n",
        "Given a citable text corpus and an orthographic system, we can tokenize the corpus.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import edu.holycross.shot.latin._\n",
        "import edu.holycross.shot.mid.validator._\n",
        "\n",
        "val tcorpus = TokenizableCorpus(corpus, Latin23Alphabet )\n",
        "val wordList =  tcorpus.wordList"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.status.busy": "2020-02-26T17:34:53.676Z",
          "iopub.execute_input": "2020-02-26T17:34:53.681Z",
          "iopub.status.idle": "2020-02-26T17:34:59.666Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zipf's Law for lexical tokens in Hyginus\n",
        "\n",
        "The `TokenizableCorpus` class includes many methods for working with a classified tokenization of a corpus.\n",
        "\n",
        "The `lexHistogram` method filters out lexical tokens and creates a histogram of them.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tcorpus.lexHistogram\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-02-26T17:34:59.678Z",
          "iopub.execute_input": "2020-02-26T17:34:59.682Z",
          "iopub.status.idle": "2020-02-26T17:35:03.460Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This histogram might be easier to interpret graphically.  We can import and use the plotly library with the ammonite shell kernel used in this notebook.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "// Make plotly libraries available to this notebook:\n",
        "import $ivy.`org.plotly-scala::plotly-almond:0.7.1`"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.status.busy": "2020-02-26T17:35:03.467Z",
          "iopub.execute_input": "2020-02-26T17:35:03.476Z",
          "iopub.status.idle": "2020-02-26T17:35:05.604Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "// Import plotly libraries, and set display defaults suggested for use in Jupyter NBs:\n",
        "import plotly._, plotly.element._, plotly.layout._, plotly.Almond._\n",
        "repl.pprinter() = repl.pprinter().copy(defaultHeight = 3)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-02-26T17:35:05.612Z",
          "iopub.execute_input": "2020-02-26T17:35:05.616Z",
          "iopub.status.idle": "2020-02-26T17:35:08.735Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val items = tcorpus.lexHistogram.frequencies.map(fr => fr.item)\n",
        "val counts = tcorpus.lexHistogram.frequencies.map(fr => fr.count)\n",
        "val zipfTokens = Vector(\n",
        "  Bar(x = items, y = counts)\n",
        ")\n",
        "plot(zipfTokens)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-02-26T17:35:17.611Z",
          "iopub.execute_input": "2020-02-26T17:35:17.615Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Scala (2.12)",
      "language": "scala",
      "name": "scala212"
    },
    "language_info": {
      "name": "scala",
      "version": "2.12.10",
      "mimetype": "text/x-scala",
      "file_extension": ".scala",
      "nbconvert_exporter": "script",
      "codemirror_mode": "text/x-scala"
    },
    "nteract": {
      "version": "0.22.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}